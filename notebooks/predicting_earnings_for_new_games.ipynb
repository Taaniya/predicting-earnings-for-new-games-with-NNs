{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Taaniya\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['critic_rating', 'is_action', 'is_exclusive_to_us', 'is_portable',\n",
      "       'is_role_playing', 'is_sequel', 'is_sports', 'suitable_for_kids',\n",
      "       'total_earnings', 'unit_price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "input_training_df = pd.read_csv(\"./data/sales_data_training.csv\",dtype=float)\n",
    "input_test_df = pd.read_csv(\"./data/sales_data_test.csv\",dtype=float)\n",
    "\n",
    "print(input_training_df.columns)\n",
    "\n",
    "# Extract features from training/test dataset\n",
    "X_training = input_training_df.drop(\"total_earnings\",axis=1).values\n",
    "Y_training = input_training_df[['total_earnings']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      "critic_rating         1000 non-null float64\n",
      "is_action             1000 non-null float64\n",
      "is_exclusive_to_us    1000 non-null float64\n",
      "is_portable           1000 non-null float64\n",
      "is_role_playing       1000 non-null float64\n",
      "is_sequel             1000 non-null float64\n",
      "is_sports             1000 non-null float64\n",
      "suitable_for_kids     1000 non-null float64\n",
      "total_earnings        1000 non-null float64\n",
      "unit_price            1000 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "input_training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_training_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale values of training dataset between 0 and 1\n",
    "# create scaler instances for x and y separately\n",
    "\n",
    "X_scaler_instance = MinMaxScaler(feature_range=(0,1))\n",
    "Y_scaler_instance = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Create scalers from training data\n",
    "X_training_scaled = X_scaler_instance.fit_transform(X_training)\n",
    "Y_training_scaled = Y_scaler_instance.fit_transform(Y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the scalers fitted from training data on the test data so that the \n",
    "# test data is scaled by the same amount as the training data\n",
    "\n",
    "X_test = input_test_df.drop('total_earnings',axis=1).values\n",
    "Y_test = input_test_df[['total_earnings']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = X_scaler_instance.transform(X_test)\n",
    "Y_test_scaled = Y_scaler_instance.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = \"run_3 50 with histogram summary\"\n",
    "\n",
    "# Define the neural network structure\n",
    "\n",
    "# training parameters\n",
    "learning_rate = 0.001\n",
    "training_epoch = 100\n",
    "display_step = 5\n",
    "\n",
    "# input/outputs\n",
    "num_inputs = 9                             # no. of features/columns for each row in the dataset\n",
    "num_outputs = 1\n",
    "\n",
    "\n",
    "# define layer sizes i.e no. of nodes in each layer.\n",
    "layer_1_nodes = 50\n",
    "layer_2_nodes = 100\n",
    "layer_3_nodes = 50\n",
    "\n",
    "# save path for exported model\n",
    "model_export_path = \"exported_model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name current cost is illegal; using current_cost instead.\n"
     ]
    }
   ],
   "source": [
    "# define all the layers of the neural network\n",
    "# input layer\n",
    "# input layer will have as many nodes as the number of features of each data row \n",
    "\n",
    "\n",
    "with tf.variable_scope(\"input\"):\n",
    "    # None tells tensorflow that our neural network can accept batches of input of any size,\n",
    "    # num_inputs will tell that there will be 9 values for each record in the batch\n",
    "    X = tf.placeholder(dtype=tf.float32,shape=(None,num_inputs))\n",
    "    \n",
    "# initialize biases with 0. Since biases is a variable, we use tf.get_variable and pass in the name.\n",
    "# 1 weight for each node's connection to each node in the layer.\n",
    "# layer 1\n",
    "with tf.variable_scope(\"layer_1\"):\n",
    "    weights = tf.get_variable(name='weights_1',shape=[num_inputs,layer_1_nodes],\n",
    "                                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name='biases_1',shape=[layer_1_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "    \n",
    "# layer 2\n",
    "with tf.variable_scope(\"layer_2\"):\n",
    "    weights = tf.get_variable(name='weights_2',shape=[layer_1_nodes,layer_2_nodes],\n",
    "                                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name='biases_2',shape=[layer_2_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output,weights) + biases)\n",
    "    \n",
    "# layer 3\n",
    "with tf.variable_scope(\"layer_3\"):\n",
    "    weights = tf.get_variable(name='weights_3',shape=[layer_2_nodes,layer_3_nodes],\n",
    "                                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name='biases_3',shape=[layer_3_nodes],initializer=tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output,weights) + biases)\n",
    "    \n",
    "    \n",
    "# output layer    \n",
    "with tf.variable_scope(\"output\"):\n",
    "    weights = tf.get_variable(name='weights_4',shape=[layer_3_nodes,num_outputs],\n",
    "                                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name='biases_4',shape=[num_outputs],initializer=tf.zeros_initializer())\n",
    "    #prediction = tf.nn.relu(tf.matmul(layer_3_output,weights) + biases)\n",
    "    prediction = tf.matmul(layer_3_output,weights) + biases\n",
    "    \n",
    "\n",
    "# define the cost function\n",
    "with tf.variable_scope(\"cost\"):\n",
    "    # target value Y\n",
    "    Y = tf.placeholder(dtype=tf.float32,shape=(None,1))\n",
    "    cost = tf.reduce_mean(tf.squared_difference(prediction,Y))\n",
    "    \n",
    "    \n",
    "# define optimizer for training\n",
    "with tf.variable_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# creating a summary operation to log progress of the network. \n",
    "# This will be a separate node in our tensorflow's computational graph\n",
    "with tf.variable_scope(\"logging\"):\n",
    "    tf.summary.scalar(\"current cost\",cost)               # pass in the name and reference to the scalar valued metric\n",
    "                                                         # we wish to monitor by logging\n",
    "    tf.summary.histogram(\"predicted_value\",prediction)\n",
    "    # adding a new node which will run all the summary nodes before this.\n",
    "    summary = tf.summary.merge_all()\n",
    "    \n",
    "    ## tf.summary.scalar object represents the value we are logging\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tf.train.saver object. Placing this code after the graph definition and befor the training loop starts    \n",
    "# saver = tf.train.Saver(keep_checkpoint_every_n_hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.variables.RefVariable"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.variables.RefVariable"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(layer_3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Operation"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.04712542 0.05172021\n",
      "5 0.027329646 0.029486189\n",
      "10 0.011682668 0.0129472185\n",
      "15 0.009341526 0.010056276\n",
      "20 0.0047228313 0.0050391443\n",
      "25 0.0028504734 0.0028570083\n",
      "30 0.0024528657 0.002458\n",
      "35 0.0019011691 0.0017832841\n",
      "40 0.0013952854 0.0014404672\n",
      "45 0.0009969122 0.00092308107\n",
      "50 0.00077021396 0.00079991005\n",
      "55 0.00062029524 0.0005768508\n",
      "60 0.0005132792 0.0005116372\n",
      "65 0.00042761097 0.00041750947\n",
      "70 0.00035584054 0.00038056195\n",
      "75 0.00029898834 0.00031730084\n",
      "80 0.00025317495 0.0002856708\n",
      "85 0.00021740625 0.00024522026\n",
      "90 0.000189262 0.0002221201\n",
      "95 0.00016669351 0.00020165999\n",
      "final training cost:0.00015156179142650217\n",
      "final testing cost:0.000188474528840743\n",
      "training is complete.\n",
      "predicted earning:[253982.5]\n",
      "actual earning:[247537]\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: exported_model\\saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# Setting up training loop\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess=sess,save_path=\"./logs/trained_model.ckpt\")\n",
    "    \n",
    "    ### create summary filewriter operation. Unlike tf.summary which create summary in protobuf format understandable by \n",
    "    ### tensorflow, this filewriter will actually write those to disk\n",
    "    ## Filewriter write summary protocol buffers to event files\n",
    "    training_logs_writer = tf.summary.FileWriter(logdir=\"./logs/{}/train\".format(RUN_NAME),graph=sess.graph)\n",
    "    testing_logs_writer = tf.summary.FileWriter(logdir=\"./logs/{}/test\".format(RUN_NAME),graph=sess.graph)\n",
    "    \n",
    "    # Running the optimizer in loop for training\n",
    "    # perform training for epochs\n",
    "    # 1 epoch is one full run through the dataset\n",
    "\n",
    "        \n",
    "    for epoch in range(training_epoch):    \n",
    "        sess.run(optimizer,feed_dict={X:X_training_scaled, Y:Y_training_scaled})\n",
    "    \n",
    "        if epoch % 5 == 0:\n",
    "            training_cost,training_summary = sess.run([cost,summary],\\\n",
    "                                                              feed_dict={X:X_training_scaled,Y:Y_training_scaled})\n",
    "            testing_cost,testing_summary = sess.run([cost,summary],\\\n",
    "                                                              feed_dict={X:X_test_scaled,Y:Y_test_scaled})\n",
    "\n",
    "            # in the steps above, we obtained the data stored in training and testing summary variables as bytes.\n",
    "            #In the next step, these summaries will be written down into log files.\n",
    "            \n",
    "            training_logs_writer.add_summary(training_summary, epoch)   # epoch values become our x-axis\n",
    "            testing_logs_writer.add_summary(testing_summary, epoch)\n",
    "            \n",
    "            print(epoch,training_cost,testing_cost)\n",
    "        \n",
    "    final_training_cost = sess.run(cost,feed_dict={X:X_training_scaled,Y:Y_training_scaled})\n",
    "    final_testing_cost = sess.run(cost,feed_dict={X:X_test_scaled,Y:Y_test_scaled})\n",
    "        \n",
    "    print(\"final training cost:{}\".format(final_training_cost))\n",
    "    print(\"final testing cost:{}\".format(final_testing_cost))\n",
    "    print(\"training is complete.\")\n",
    "        \n",
    "    predicted_earnings_scaled = sess.run(prediction, feed_dict={X:X_test_scaled,Y:Y_test_scaled})    \n",
    "    predicted_earnings = Y_scaler_instance.inverse_transform(predicted_earnings_scaled)\n",
    "    print(\"predicted earning:{}\".format(predicted_earnings[0]))    \n",
    "        \n",
    "    actual_earnings = Y_test[0]\n",
    "    \n",
    "    print(\"actual earning:{}\".format(actual_earnings))\n",
    "    # will return the path prefix of the checkpoint files\n",
    "    # saved_path = saver.save(sess=sess,save_path=\"./logs/trained_model.ckpt\")    \n",
    "    \n",
    "    # Exporting the model for deployment to cloud\n",
    "    model_builder = tf.saved_model.builder.SavedModelBuilder(model_export_path)   # this will create a new directory for the model\n",
    "    \n",
    "    # define inputs/outputs of model that we want Google to use when it runs our model on cloud\n",
    "    # Create the TensorInfo protobuf objects that encapsulates the input/output tensors\n",
    "    # We use a dictionary with our input/output nodes as keys and their TensorInfo protobuf objects as values\n",
    "    \n",
    "    inputs = {\n",
    "        'input': tf.saved_model.utils.build_tensor_info(X)\n",
    "        }\n",
    "    \n",
    "    outputs = {\n",
    "        'output': tf.saved_model.utils.build_tensor_info(prediction)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    # define signatures\n",
    "    # For prediction signature simply pass tensors that are input to the model and which are given as output from the model.\n",
    "    \n",
    "    # tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "    # A pre-defined function name. that's what Google will always look for to execute out model. \n",
    "    \n",
    "    prediction_signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    "    )\n",
    "    \n",
    "    # Next, we configure the model builder to tell it exactly how we want this model exported. \n",
    "    # metagraph - structure of our computational graph\n",
    "    # variables - values we set our each node in the graph\n",
    "    # signature def map will list all the signature defs that this model supports\n",
    "    model_builder.add_meta_graph_and_variables(\n",
    "                            sess,\n",
    "                            tags=[tf.saved_model.tag_constants.SERVING],\n",
    "                            signature_def_map={ \n",
    "                                tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY : prediction_signature_def\n",
    "                            }\n",
    "                                        )\n",
    "    \n",
    "    \n",
    "    # export the model\n",
    "    saved_path = model_builder.save(as_text=False)  # False - to be saved in serialised format otherwise in text.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 21.,  73., 103.,  74.,  62.,  21.,  19.,  16.,   7.,   4.]),\n",
       " array([-0.00170284,  0.08821211,  0.17812705,  0.268042  ,  0.35795695,\n",
       "         0.4478719 ,  0.53778684,  0.62770179,  0.71761674,  0.80753168,\n",
       "         0.89744663]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicted_earnings_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 32.,  83., 102.,  63.,  61.,  16.,  16.,  10.,  13.,   4.]),\n",
       " array([0.01795161, 0.10520804, 0.19246446, 0.27972089, 0.36697732,\n",
       "        0.45423375, 0.54149018, 0.6287466 , 0.71600303, 0.80325946,\n",
       "        0.89051589]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why xavier weight initialization\n",
    "# https://adventuresinmachinelearning.com/weight-initialization-tutorial-tensorflow/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
